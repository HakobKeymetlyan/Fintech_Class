{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "testgv",
      "language": "python",
      "name": "testgv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "M1_Smartphone_Activity_Detector.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwHZMksSby0C"
      },
      "source": [
        "# Neural Network Smartphone Activity Detector\n",
        "\n",
        "In this activity, you will train a neural network to use smartphone data to predict the activity of the user. \n",
        "\n",
        "This dataset has already been separated into input features and target activities. Additional information on the dataset can be found here. \n",
        "\n",
        "http://archive.ics.uci.edu/ml/datasets/Smartphone-Based+Recognition+of+Human+Activities+and+Postural+Transitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFfrsfVyby0F"
      },
      "source": [
        "### Data Pre-Processing\n",
        "\n",
        "Prepare the data for the neural network. This includes splitting the data into a training and testing dataset, Scaling the data, and encoding the categorical target values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoXtMPdJby0G"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "sVTrTawMb2ul",
        "outputId": "5b4cd3a3-f9b1-42ce-a203-7a784be13a88"
      },
      "source": [
        "# Upload data to Colab\n",
        "from google.colab import files\n",
        "\n",
        "csv_file = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6db4337d-8e86-482c-8207-0b55358c592c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6db4337d-8e86-482c-8207-0b55358c592c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving features.csv to features (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "i2uJV_X2by0G",
        "outputId": "aab6e1e8-9677-4384-d246-c81d9ae51673"
      },
      "source": [
        "# Read the input features into `X`\n",
        "X = pd.read_csv(\"features.csv\")\n",
        "X.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tBodyAcc-Mean-1</th>\n",
              "      <th>tBodyAcc-Mean-2</th>\n",
              "      <th>tBodyAcc-Mean-3</th>\n",
              "      <th>tBodyAcc-STD-1</th>\n",
              "      <th>tBodyAcc-STD-2</th>\n",
              "      <th>tBodyAcc-STD-3</th>\n",
              "      <th>tBodyAcc-Mad-1</th>\n",
              "      <th>tBodyAcc-Mad-2</th>\n",
              "      <th>tBodyAcc-Mad-3</th>\n",
              "      <th>tBodyAcc-Max-1</th>\n",
              "      <th>tBodyAcc-Max-2</th>\n",
              "      <th>tBodyAcc-Max-3</th>\n",
              "      <th>tBodyAcc-Min-1</th>\n",
              "      <th>tBodyAcc-Min-2</th>\n",
              "      <th>tBodyAcc-Min-3</th>\n",
              "      <th>tBodyAcc-SMA-1</th>\n",
              "      <th>tBodyAcc-Energy-1</th>\n",
              "      <th>tBodyAcc-Energy-2</th>\n",
              "      <th>tBodyAcc-Energy-3</th>\n",
              "      <th>tBodyAcc-IQR-1</th>\n",
              "      <th>tBodyAcc-IQR-2</th>\n",
              "      <th>tBodyAcc-IQR-3</th>\n",
              "      <th>tBodyAcc-ropy-1</th>\n",
              "      <th>tBodyAcc-ropy-1.1</th>\n",
              "      <th>tBodyAcc-ropy-1.2</th>\n",
              "      <th>tBodyAcc-ARCoeff-1</th>\n",
              "      <th>tBodyAcc-ARCoeff-2</th>\n",
              "      <th>tBodyAcc-ARCoeff-3</th>\n",
              "      <th>tBodyAcc-ARCoeff-4</th>\n",
              "      <th>tBodyAcc-ARCoeff-5</th>\n",
              "      <th>tBodyAcc-ARCoeff-6</th>\n",
              "      <th>tBodyAcc-ARCoeff-7</th>\n",
              "      <th>tBodyAcc-ARCoeff-8</th>\n",
              "      <th>tBodyAcc-ARCoeff-9</th>\n",
              "      <th>tBodyAcc-ARCoeff-10</th>\n",
              "      <th>tBodyAcc-ARCoeff-11</th>\n",
              "      <th>tBodyAcc-ARCoeff-12</th>\n",
              "      <th>tBodyAcc-Correlation-1</th>\n",
              "      <th>tBodyAcc-Correlation-2</th>\n",
              "      <th>tBodyAcc-Correlation-3</th>\n",
              "      <th>...</th>\n",
              "      <th>fBodyAccJerkMag-Energy-1</th>\n",
              "      <th>fBodyAccJerkMag-IQR-1</th>\n",
              "      <th>fBodyAccJerkMag-ropy-1</th>\n",
              "      <th>fBodyAccJerkMag-MaxInds-1</th>\n",
              "      <th>fBodyAccJerkMag-MeanFreq-1</th>\n",
              "      <th>fBodyAccJerkMag-Skewness-1</th>\n",
              "      <th>fBodyAccJerkMag-Kurtosis-1</th>\n",
              "      <th>fBodyGyroMag-Mean-1</th>\n",
              "      <th>fBodyGyroMag-STD-1</th>\n",
              "      <th>fBodyGyroMag-Mad-1</th>\n",
              "      <th>fBodyGyroMag-Max-1</th>\n",
              "      <th>fBodyGyroMag-Min-1</th>\n",
              "      <th>fBodyGyroMag-SMA-1</th>\n",
              "      <th>fBodyGyroMag-Energy-1</th>\n",
              "      <th>fBodyGyroMag-IQR-1</th>\n",
              "      <th>fBodyGyroMag-ropy-1</th>\n",
              "      <th>fBodyGyroMag-MaxInds-1</th>\n",
              "      <th>fBodyGyroMag-MeanFreq-1</th>\n",
              "      <th>fBodyGyroMag-Skewness-1</th>\n",
              "      <th>fBodyGyroMag-Kurtosis-1</th>\n",
              "      <th>fBodyGyroJerkMag-Mean-1</th>\n",
              "      <th>fBodyGyroJerkMag-STD-1</th>\n",
              "      <th>fBodyGyroJerkMag-Mad-1</th>\n",
              "      <th>fBodyGyroJerkMag-Max-1</th>\n",
              "      <th>fBodyGyroJerkMag-Min-1</th>\n",
              "      <th>fBodyGyroJerkMag-SMA-1</th>\n",
              "      <th>fBodyGyroJerkMag-Energy-1</th>\n",
              "      <th>fBodyGyroJerkMag-IQR-1</th>\n",
              "      <th>fBodyGyroJerkMag-ropy-1</th>\n",
              "      <th>fBodyGyroJerkMag-MaxInds-1</th>\n",
              "      <th>fBodyGyroJerkMag-MeanFreq-1</th>\n",
              "      <th>fBodyGyroJerkMag-Skewness-1</th>\n",
              "      <th>fBodyGyroJerkMag-Kurtosis-1</th>\n",
              "      <th>tBodyAcc-AngleWRTGravity-1</th>\n",
              "      <th>tBodyAccJerk-AngleWRTGravity-1</th>\n",
              "      <th>tBodyGyro-AngleWRTGravity-1</th>\n",
              "      <th>tBodyGyroJerk-AngleWRTGravity-1</th>\n",
              "      <th>tXAxisAcc-AngleWRTGravity-1</th>\n",
              "      <th>tYAxisAcc-AngleWRTGravity-1</th>\n",
              "      <th>tZAxisAcc-AngleWRTGravity-1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.043580</td>\n",
              "      <td>-0.005970</td>\n",
              "      <td>-0.035054</td>\n",
              "      <td>-0.995381</td>\n",
              "      <td>-0.988366</td>\n",
              "      <td>-0.937382</td>\n",
              "      <td>-0.995007</td>\n",
              "      <td>-0.988816</td>\n",
              "      <td>-0.953325</td>\n",
              "      <td>-0.794796</td>\n",
              "      <td>-0.744893</td>\n",
              "      <td>-0.648447</td>\n",
              "      <td>0.841796</td>\n",
              "      <td>0.708440</td>\n",
              "      <td>0.651716</td>\n",
              "      <td>-0.975752</td>\n",
              "      <td>-0.999950</td>\n",
              "      <td>-0.999888</td>\n",
              "      <td>-0.998014</td>\n",
              "      <td>-0.993999</td>\n",
              "      <td>-0.991980</td>\n",
              "      <td>-0.970970</td>\n",
              "      <td>-0.547095</td>\n",
              "      <td>-0.700974</td>\n",
              "      <td>-0.622697</td>\n",
              "      <td>0.921884</td>\n",
              "      <td>-0.719483</td>\n",
              "      <td>0.342168</td>\n",
              "      <td>-0.161318</td>\n",
              "      <td>0.266049</td>\n",
              "      <td>-0.274351</td>\n",
              "      <td>0.267205</td>\n",
              "      <td>-0.020958</td>\n",
              "      <td>0.382610</td>\n",
              "      <td>-0.501748</td>\n",
              "      <td>0.512463</td>\n",
              "      <td>-0.206337</td>\n",
              "      <td>0.376778</td>\n",
              "      <td>0.435172</td>\n",
              "      <td>0.660199</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999918</td>\n",
              "      <td>-0.991736</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.936508</td>\n",
              "      <td>0.349260</td>\n",
              "      <td>-0.517127</td>\n",
              "      <td>-0.801006</td>\n",
              "      <td>-0.980135</td>\n",
              "      <td>-0.961301</td>\n",
              "      <td>-0.974129</td>\n",
              "      <td>-0.956013</td>\n",
              "      <td>-0.989894</td>\n",
              "      <td>-0.980135</td>\n",
              "      <td>-0.999240</td>\n",
              "      <td>-0.992673</td>\n",
              "      <td>-0.701291</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.132480</td>\n",
              "      <td>0.565697</td>\n",
              "      <td>0.363478</td>\n",
              "      <td>-0.991994</td>\n",
              "      <td>-0.990877</td>\n",
              "      <td>-0.990169</td>\n",
              "      <td>-0.992521</td>\n",
              "      <td>-0.991044</td>\n",
              "      <td>-0.991994</td>\n",
              "      <td>-0.999937</td>\n",
              "      <td>-0.990537</td>\n",
              "      <td>-0.871306</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.012236</td>\n",
              "      <td>-0.314848</td>\n",
              "      <td>-0.713308</td>\n",
              "      <td>-0.112754</td>\n",
              "      <td>0.030400</td>\n",
              "      <td>-0.464761</td>\n",
              "      <td>-0.018446</td>\n",
              "      <td>-0.841559</td>\n",
              "      <td>0.179913</td>\n",
              "      <td>-0.051718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.039480</td>\n",
              "      <td>-0.002131</td>\n",
              "      <td>-0.029067</td>\n",
              "      <td>-0.998348</td>\n",
              "      <td>-0.982945</td>\n",
              "      <td>-0.971273</td>\n",
              "      <td>-0.998702</td>\n",
              "      <td>-0.983315</td>\n",
              "      <td>-0.974000</td>\n",
              "      <td>-0.802537</td>\n",
              "      <td>-0.736338</td>\n",
              "      <td>-0.712415</td>\n",
              "      <td>0.838758</td>\n",
              "      <td>0.708440</td>\n",
              "      <td>0.659340</td>\n",
              "      <td>-0.987427</td>\n",
              "      <td>-0.999993</td>\n",
              "      <td>-0.999826</td>\n",
              "      <td>-0.999411</td>\n",
              "      <td>-0.998918</td>\n",
              "      <td>-0.985482</td>\n",
              "      <td>-0.973481</td>\n",
              "      <td>-0.781973</td>\n",
              "      <td>-0.534604</td>\n",
              "      <td>-0.593165</td>\n",
              "      <td>0.607435</td>\n",
              "      <td>-0.266783</td>\n",
              "      <td>0.275882</td>\n",
              "      <td>0.200417</td>\n",
              "      <td>0.131266</td>\n",
              "      <td>-0.149017</td>\n",
              "      <td>0.292436</td>\n",
              "      <td>-0.192986</td>\n",
              "      <td>0.217496</td>\n",
              "      <td>-0.089175</td>\n",
              "      <td>0.059909</td>\n",
              "      <td>-0.236609</td>\n",
              "      <td>-0.012696</td>\n",
              "      <td>-0.072711</td>\n",
              "      <td>0.578649</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999867</td>\n",
              "      <td>-0.991506</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.841270</td>\n",
              "      <td>0.533688</td>\n",
              "      <td>-0.625993</td>\n",
              "      <td>-0.898311</td>\n",
              "      <td>-0.988296</td>\n",
              "      <td>-0.983313</td>\n",
              "      <td>-0.982951</td>\n",
              "      <td>-0.987406</td>\n",
              "      <td>-0.992134</td>\n",
              "      <td>-0.988296</td>\n",
              "      <td>-0.999811</td>\n",
              "      <td>-0.993996</td>\n",
              "      <td>-0.720683</td>\n",
              "      <td>-0.948718</td>\n",
              "      <td>-0.268979</td>\n",
              "      <td>-0.364219</td>\n",
              "      <td>-0.723724</td>\n",
              "      <td>-0.995857</td>\n",
              "      <td>-0.996580</td>\n",
              "      <td>-0.995671</td>\n",
              "      <td>-0.996939</td>\n",
              "      <td>-0.994436</td>\n",
              "      <td>-0.995857</td>\n",
              "      <td>-0.999981</td>\n",
              "      <td>-0.994623</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.202804</td>\n",
              "      <td>-0.603199</td>\n",
              "      <td>-0.860677</td>\n",
              "      <td>0.053477</td>\n",
              "      <td>-0.007435</td>\n",
              "      <td>-0.732626</td>\n",
              "      <td>0.703511</td>\n",
              "      <td>-0.845092</td>\n",
              "      <td>0.180261</td>\n",
              "      <td>-0.047436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.039978</td>\n",
              "      <td>-0.005153</td>\n",
              "      <td>-0.022651</td>\n",
              "      <td>-0.995482</td>\n",
              "      <td>-0.977314</td>\n",
              "      <td>-0.984760</td>\n",
              "      <td>-0.996415</td>\n",
              "      <td>-0.975835</td>\n",
              "      <td>-0.985973</td>\n",
              "      <td>-0.798477</td>\n",
              "      <td>-0.736338</td>\n",
              "      <td>-0.712415</td>\n",
              "      <td>0.834002</td>\n",
              "      <td>0.705008</td>\n",
              "      <td>0.674551</td>\n",
              "      <td>-0.988528</td>\n",
              "      <td>-0.999972</td>\n",
              "      <td>-0.999719</td>\n",
              "      <td>-0.999803</td>\n",
              "      <td>-0.996898</td>\n",
              "      <td>-0.976781</td>\n",
              "      <td>-0.986754</td>\n",
              "      <td>-0.688176</td>\n",
              "      <td>-0.520514</td>\n",
              "      <td>-0.593165</td>\n",
              "      <td>0.272262</td>\n",
              "      <td>-0.056424</td>\n",
              "      <td>0.322283</td>\n",
              "      <td>-0.273292</td>\n",
              "      <td>0.037180</td>\n",
              "      <td>-0.133612</td>\n",
              "      <td>0.332487</td>\n",
              "      <td>-0.240491</td>\n",
              "      <td>0.348733</td>\n",
              "      <td>-0.195409</td>\n",
              "      <td>0.229436</td>\n",
              "      <td>-0.316816</td>\n",
              "      <td>-0.123889</td>\n",
              "      <td>-0.181137</td>\n",
              "      <td>0.608219</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999845</td>\n",
              "      <td>-0.987029</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>0.661975</td>\n",
              "      <td>-0.725887</td>\n",
              "      <td>-0.926663</td>\n",
              "      <td>-0.989255</td>\n",
              "      <td>-0.986019</td>\n",
              "      <td>-0.984533</td>\n",
              "      <td>-0.991701</td>\n",
              "      <td>-0.995857</td>\n",
              "      <td>-0.989255</td>\n",
              "      <td>-0.999854</td>\n",
              "      <td>-0.993256</td>\n",
              "      <td>-0.736521</td>\n",
              "      <td>-0.794872</td>\n",
              "      <td>-0.212429</td>\n",
              "      <td>-0.564868</td>\n",
              "      <td>-0.874594</td>\n",
              "      <td>-0.995034</td>\n",
              "      <td>-0.995308</td>\n",
              "      <td>-0.994868</td>\n",
              "      <td>-0.996133</td>\n",
              "      <td>-0.995863</td>\n",
              "      <td>-0.995034</td>\n",
              "      <td>-0.999973</td>\n",
              "      <td>-0.993834</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.555556</td>\n",
              "      <td>0.440079</td>\n",
              "      <td>-0.404427</td>\n",
              "      <td>-0.761847</td>\n",
              "      <td>-0.118559</td>\n",
              "      <td>0.177899</td>\n",
              "      <td>0.100699</td>\n",
              "      <td>0.808529</td>\n",
              "      <td>-0.849230</td>\n",
              "      <td>0.180610</td>\n",
              "      <td>-0.042271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.039785</td>\n",
              "      <td>-0.011809</td>\n",
              "      <td>-0.028916</td>\n",
              "      <td>-0.996194</td>\n",
              "      <td>-0.988569</td>\n",
              "      <td>-0.993256</td>\n",
              "      <td>-0.996994</td>\n",
              "      <td>-0.988526</td>\n",
              "      <td>-0.993135</td>\n",
              "      <td>-0.798477</td>\n",
              "      <td>-0.752778</td>\n",
              "      <td>-0.722186</td>\n",
              "      <td>0.834002</td>\n",
              "      <td>0.705008</td>\n",
              "      <td>0.673208</td>\n",
              "      <td>-0.990389</td>\n",
              "      <td>-0.999978</td>\n",
              "      <td>-0.999783</td>\n",
              "      <td>-0.999815</td>\n",
              "      <td>-0.996949</td>\n",
              "      <td>-0.989437</td>\n",
              "      <td>-0.992440</td>\n",
              "      <td>-0.715103</td>\n",
              "      <td>-0.860988</td>\n",
              "      <td>-0.916429</td>\n",
              "      <td>0.062816</td>\n",
              "      <td>0.082940</td>\n",
              "      <td>0.200566</td>\n",
              "      <td>-0.378262</td>\n",
              "      <td>0.090063</td>\n",
              "      <td>-0.209264</td>\n",
              "      <td>0.316530</td>\n",
              "      <td>-0.090862</td>\n",
              "      <td>0.396383</td>\n",
              "      <td>-0.353643</td>\n",
              "      <td>0.503754</td>\n",
              "      <td>-0.490389</td>\n",
              "      <td>-0.304759</td>\n",
              "      <td>-0.362708</td>\n",
              "      <td>0.506602</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999894</td>\n",
              "      <td>-0.988427</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.680038</td>\n",
              "      <td>-0.702305</td>\n",
              "      <td>-0.907781</td>\n",
              "      <td>-0.989413</td>\n",
              "      <td>-0.987827</td>\n",
              "      <td>-0.987057</td>\n",
              "      <td>-0.987801</td>\n",
              "      <td>-0.996334</td>\n",
              "      <td>-0.989413</td>\n",
              "      <td>-0.999876</td>\n",
              "      <td>-0.989153</td>\n",
              "      <td>-0.720891</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.043398</td>\n",
              "      <td>-0.257142</td>\n",
              "      <td>-0.516341</td>\n",
              "      <td>-0.995224</td>\n",
              "      <td>-0.995417</td>\n",
              "      <td>-0.995951</td>\n",
              "      <td>-0.995346</td>\n",
              "      <td>-0.995728</td>\n",
              "      <td>-0.995224</td>\n",
              "      <td>-0.999974</td>\n",
              "      <td>-0.995305</td>\n",
              "      <td>-0.955696</td>\n",
              "      <td>-0.936508</td>\n",
              "      <td>0.430891</td>\n",
              "      <td>-0.138373</td>\n",
              "      <td>-0.491604</td>\n",
              "      <td>-0.036788</td>\n",
              "      <td>-0.012892</td>\n",
              "      <td>0.640011</td>\n",
              "      <td>-0.485366</td>\n",
              "      <td>-0.848947</td>\n",
              "      <td>0.181907</td>\n",
              "      <td>-0.040826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.038758</td>\n",
              "      <td>-0.002289</td>\n",
              "      <td>-0.023863</td>\n",
              "      <td>-0.998241</td>\n",
              "      <td>-0.986774</td>\n",
              "      <td>-0.993115</td>\n",
              "      <td>-0.998216</td>\n",
              "      <td>-0.986479</td>\n",
              "      <td>-0.993825</td>\n",
              "      <td>-0.801982</td>\n",
              "      <td>-0.746505</td>\n",
              "      <td>-0.717858</td>\n",
              "      <td>0.838581</td>\n",
              "      <td>0.705854</td>\n",
              "      <td>0.673208</td>\n",
              "      <td>-0.995057</td>\n",
              "      <td>-0.999992</td>\n",
              "      <td>-0.999882</td>\n",
              "      <td>-0.999908</td>\n",
              "      <td>-0.997772</td>\n",
              "      <td>-0.987726</td>\n",
              "      <td>-0.995109</td>\n",
              "      <td>-0.836774</td>\n",
              "      <td>-0.589200</td>\n",
              "      <td>-0.773771</td>\n",
              "      <td>0.312105</td>\n",
              "      <td>-0.095254</td>\n",
              "      <td>0.194399</td>\n",
              "      <td>-0.007998</td>\n",
              "      <td>0.266740</td>\n",
              "      <td>-0.318965</td>\n",
              "      <td>0.409731</td>\n",
              "      <td>-0.224589</td>\n",
              "      <td>0.520354</td>\n",
              "      <td>-0.319167</td>\n",
              "      <td>0.234376</td>\n",
              "      <td>-0.102650</td>\n",
              "      <td>-0.154974</td>\n",
              "      <td>-0.189796</td>\n",
              "      <td>0.598515</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999941</td>\n",
              "      <td>-0.994542</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.560592</td>\n",
              "      <td>-0.529957</td>\n",
              "      <td>-0.857124</td>\n",
              "      <td>-0.991433</td>\n",
              "      <td>-0.989051</td>\n",
              "      <td>-0.987932</td>\n",
              "      <td>-0.992145</td>\n",
              "      <td>-0.998404</td>\n",
              "      <td>-0.991433</td>\n",
              "      <td>-0.999902</td>\n",
              "      <td>-0.989339</td>\n",
              "      <td>-0.763372</td>\n",
              "      <td>-0.897436</td>\n",
              "      <td>-0.270529</td>\n",
              "      <td>-0.539596</td>\n",
              "      <td>-0.833661</td>\n",
              "      <td>-0.995096</td>\n",
              "      <td>-0.995645</td>\n",
              "      <td>-0.995508</td>\n",
              "      <td>-0.995683</td>\n",
              "      <td>-0.997414</td>\n",
              "      <td>-0.995096</td>\n",
              "      <td>-0.999974</td>\n",
              "      <td>-0.995566</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.936508</td>\n",
              "      <td>0.137735</td>\n",
              "      <td>-0.366214</td>\n",
              "      <td>-0.702490</td>\n",
              "      <td>0.123320</td>\n",
              "      <td>0.122542</td>\n",
              "      <td>0.693578</td>\n",
              "      <td>-0.615971</td>\n",
              "      <td>-0.848164</td>\n",
              "      <td>0.185124</td>\n",
              "      <td>-0.037080</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 561 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   tBodyAcc-Mean-1  ...  tZAxisAcc-AngleWRTGravity-1\n",
              "0         0.043580  ...                    -0.051718\n",
              "1         0.039480  ...                    -0.047436\n",
              "2         0.039978  ...                    -0.042271\n",
              "3         0.039785  ...                    -0.040826\n",
              "4         0.038758  ...                    -0.037080\n",
              "\n",
              "[5 rows x 561 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "dVzqGN06cFhE",
        "outputId": "110c5c4c-e0db-471e-c3d3-6736bbae6a57"
      },
      "source": [
        "# Upload data to Colab\n",
        "csv_file = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0812144f-093a-4586-a1ff-92a79cd879c2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0812144f-093a-4586-a1ff-92a79cd879c2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving target.csv to target.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "dNwj6V7kby0H",
        "outputId": "c97f0848-0d33-4eaf-ed1c-138c024531ba"
      },
      "source": [
        "# Read the target values into `y`\n",
        "y = pd.read_csv(\"target.csv\")\n",
        "y.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>standing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>standing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>standing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>standing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>standing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   activity\n",
              "0  standing\n",
              "1  standing\n",
              "2  standing\n",
              "3  standing\n",
              "4  standing"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EVCLESQby0I",
        "outputId": "4efe685e-1039-4c6c-ad4c-beda730aff31"
      },
      "source": [
        "y.activity.value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "standing              1423\n",
              "laying                1413\n",
              "sitting               1293\n",
              "walking               1226\n",
              "walking_upstairs      1073\n",
              "walking_downstairs     987\n",
              "stand_to_lie            90\n",
              "sit_to_lie              75\n",
              "lie_to_sit              60\n",
              "lie_to_stand            57\n",
              "stand_to_sit            47\n",
              "sit_to_stand            23\n",
              "Name: activity, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW1tnHBQby0I"
      },
      "source": [
        "# Split the dataset into training and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acErW392by0J"
      },
      "source": [
        "# Scale the training and testing input features using StandardScaler\n",
        "X_scaler = StandardScaler()\n",
        "X_scaler.fit(X_train)\n",
        "\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFWQpw3Wby0J",
        "outputId": "c5dc369d-a3b2-4ed5-b6dd-a5f2409e7641"
      },
      "source": [
        "# Apply One-hot encoding to the target labels\n",
        "enc = OneHotEncoder()\n",
        "enc.fit(y_train)\n",
        "\n",
        "encoded_y_train = enc.transform(y_train).toarray()\n",
        "encoded_y_test = enc.transform(y_test).toarray()\n",
        "encoded_y_train[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPE6GHzhby0K"
      },
      "source": [
        "# Build a Deep Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LyIVL2Pby0K"
      },
      "source": [
        "# Create a sequential model\n",
        "model = Sequential()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BflNy17by0L"
      },
      "source": [
        "# Add the first layer where the input dimensions are the 561 columns of the training data\n",
        "model.add(Dense(100, activation='relu', input_dim=X_train_scaled.shape[1]))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnYSEvJvby0L"
      },
      "source": [
        "# The output layer has 12 columns that are one-hot encoded\n",
        "y_train.activity.value_counts()\n",
        "number_outputs = 12"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7e2oa11by0L"
      },
      "source": [
        "# Add output layer using 12 output nodes\n",
        "model.add(Dense(number_outputs, activation=\"softmax\"))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgAlZYkdby0L"
      },
      "source": [
        "# Compile the model using categorical_crossentropy for the loss function, the adam optimizer,\n",
        "# and add accuracy to the training metrics\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EXEt8AQby0M",
        "outputId": "65ddc31d-f5a6-41bd-cee5-1a46d9619b67"
      },
      "source": [
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 100)               56200     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 12)                1212      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 57,412\n",
            "Trainable params: 57,412\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CF2DJZRby0M",
        "outputId": "e9770df9-6edf-4367-f27b-06a81ee8f61d"
      },
      "source": [
        "# Use the training data to fit (train) the model\n",
        "# @NOTE: Experiment with the number of training epochs to find the minimum iterations required to achieve a good accuracy\n",
        "model.fit(\n",
        "    X_train_scaled,\n",
        "    encoded_y_train,\n",
        "    epochs=30,\n",
        "    shuffle=True,\n",
        "    verbose=2\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "183/183 - 1s - loss: 0.3757 - accuracy: 0.8748 - 1s/epoch - 6ms/step\n",
            "Epoch 2/30\n",
            "183/183 - 0s - loss: 0.1250 - accuracy: 0.9579 - 348ms/epoch - 2ms/step\n",
            "Epoch 3/30\n",
            "183/183 - 0s - loss: 0.0864 - accuracy: 0.9691 - 313ms/epoch - 2ms/step\n",
            "Epoch 4/30\n",
            "183/183 - 0s - loss: 0.0657 - accuracy: 0.9782 - 332ms/epoch - 2ms/step\n",
            "Epoch 5/30\n",
            "183/183 - 0s - loss: 0.0556 - accuracy: 0.9808 - 305ms/epoch - 2ms/step\n",
            "Epoch 6/30\n",
            "183/183 - 0s - loss: 0.0505 - accuracy: 0.9827 - 330ms/epoch - 2ms/step\n",
            "Epoch 7/30\n",
            "183/183 - 0s - loss: 0.0594 - accuracy: 0.9789 - 312ms/epoch - 2ms/step\n",
            "Epoch 8/30\n",
            "183/183 - 0s - loss: 0.0361 - accuracy: 0.9871 - 328ms/epoch - 2ms/step\n",
            "Epoch 9/30\n",
            "183/183 - 0s - loss: 0.0402 - accuracy: 0.9845 - 313ms/epoch - 2ms/step\n",
            "Epoch 10/30\n",
            "183/183 - 0s - loss: 0.0295 - accuracy: 0.9900 - 325ms/epoch - 2ms/step\n",
            "Epoch 11/30\n",
            "183/183 - 0s - loss: 0.0258 - accuracy: 0.9918 - 320ms/epoch - 2ms/step\n",
            "Epoch 12/30\n",
            "183/183 - 0s - loss: 0.0187 - accuracy: 0.9940 - 336ms/epoch - 2ms/step\n",
            "Epoch 13/30\n",
            "183/183 - 0s - loss: 0.0179 - accuracy: 0.9948 - 310ms/epoch - 2ms/step\n",
            "Epoch 14/30\n",
            "183/183 - 0s - loss: 0.0157 - accuracy: 0.9952 - 333ms/epoch - 2ms/step\n",
            "Epoch 15/30\n",
            "183/183 - 0s - loss: 0.0575 - accuracy: 0.9839 - 316ms/epoch - 2ms/step\n",
            "Epoch 16/30\n",
            "183/183 - 0s - loss: 0.0204 - accuracy: 0.9928 - 302ms/epoch - 2ms/step\n",
            "Epoch 17/30\n",
            "183/183 - 0s - loss: 0.0156 - accuracy: 0.9955 - 332ms/epoch - 2ms/step\n",
            "Epoch 18/30\n",
            "183/183 - 0s - loss: 0.0064 - accuracy: 0.9991 - 336ms/epoch - 2ms/step\n",
            "Epoch 19/30\n",
            "183/183 - 0s - loss: 0.0107 - accuracy: 0.9962 - 329ms/epoch - 2ms/step\n",
            "Epoch 20/30\n",
            "183/183 - 0s - loss: 0.0103 - accuracy: 0.9959 - 328ms/epoch - 2ms/step\n",
            "Epoch 21/30\n",
            "183/183 - 0s - loss: 0.0061 - accuracy: 0.9985 - 315ms/epoch - 2ms/step\n",
            "Epoch 22/30\n",
            "183/183 - 0s - loss: 0.0031 - accuracy: 1.0000 - 312ms/epoch - 2ms/step\n",
            "Epoch 23/30\n",
            "183/183 - 0s - loss: 0.0023 - accuracy: 1.0000 - 322ms/epoch - 2ms/step\n",
            "Epoch 24/30\n",
            "183/183 - 0s - loss: 0.0055 - accuracy: 0.9986 - 332ms/epoch - 2ms/step\n",
            "Epoch 25/30\n",
            "183/183 - 0s - loss: 0.0062 - accuracy: 0.9978 - 306ms/epoch - 2ms/step\n",
            "Epoch 26/30\n",
            "183/183 - 0s - loss: 0.0032 - accuracy: 1.0000 - 331ms/epoch - 2ms/step\n",
            "Epoch 27/30\n",
            "183/183 - 0s - loss: 0.0120 - accuracy: 0.9959 - 294ms/epoch - 2ms/step\n",
            "Epoch 28/30\n",
            "183/183 - 0s - loss: 0.0213 - accuracy: 0.9916 - 302ms/epoch - 2ms/step\n",
            "Epoch 29/30\n",
            "183/183 - 0s - loss: 0.0614 - accuracy: 0.9837 - 320ms/epoch - 2ms/step\n",
            "Epoch 30/30\n",
            "183/183 - 0s - loss: 0.0104 - accuracy: 0.9967 - 311ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdf0e3df610>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EVU5sjXby0M"
      },
      "source": [
        "# Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZcCOx_6by0N",
        "outputId": "59738161-7db9-402c-af66-0f9f27511ae9"
      },
      "source": [
        "# Evaluate the model using the testing data\n",
        "model_loss, model_accuracy = model.evaluate(X_test_scaled, encoded_y_test, verbose=2)\n",
        "print(f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61/61 - 0s - loss: 0.0711 - accuracy: 0.9743 - 233ms/epoch - 4ms/step\n",
            "Normal Neural Network - Loss: 0.07110808044672012, Accuracy: 0.9742533564567566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "avSV9EMzby0N",
        "outputId": "cf501092-d825-4505-9cd2-445e6c657841"
      },
      "source": [
        "# Make predictions\n",
        "predicted = model.predict(X_test_scaled)\n",
        "predicted = enc.inverse_transform(predicted).flatten().tolist()\n",
        "results = pd.DataFrame({\n",
        "    \"Actual\": y_test.activity.values,\n",
        "    \"Predicted\": predicted\n",
        "})\n",
        "results.head(10)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>walking_upstairs</td>\n",
              "      <td>walking_upstairs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>laying</td>\n",
              "      <td>laying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sitting</td>\n",
              "      <td>sitting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sitting</td>\n",
              "      <td>sitting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>walking</td>\n",
              "      <td>walking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sitting</td>\n",
              "      <td>sitting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lie_to_sit</td>\n",
              "      <td>lie_to_sit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>walking_downstairs</td>\n",
              "      <td>walking_downstairs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>laying</td>\n",
              "      <td>laying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sitting</td>\n",
              "      <td>sitting</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Actual           Predicted\n",
              "0    walking_upstairs    walking_upstairs\n",
              "1              laying              laying\n",
              "2             sitting             sitting\n",
              "3             sitting             sitting\n",
              "4             walking             walking\n",
              "5             sitting             sitting\n",
              "6          lie_to_sit          lie_to_sit\n",
              "7  walking_downstairs  walking_downstairs\n",
              "8              laying              laying\n",
              "9             sitting             sitting"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFK018UIby0N",
        "outputId": "6af8dff5-b8b4-4071-f9cb-8534fb6a2d55"
      },
      "source": [
        "# Print the Classification Report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(results.Actual, results.Predicted))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    precision    recall  f1-score   support\n",
            "\n",
            "            laying       1.00      1.00      1.00       355\n",
            "        lie_to_sit       1.00      0.80      0.89        15\n",
            "      lie_to_stand       0.79      1.00      0.88        11\n",
            "        sit_to_lie       0.85      0.74      0.79        23\n",
            "      sit_to_stand       1.00      1.00      1.00         4\n",
            "           sitting       0.96      0.95      0.95       337\n",
            "      stand_to_lie       0.72      0.72      0.72        18\n",
            "      stand_to_sit       0.87      0.87      0.87        15\n",
            "          standing       0.95      0.97      0.96       367\n",
            "           walking       1.00      0.99      0.99       300\n",
            "walking_downstairs       0.99      1.00      1.00       230\n",
            "  walking_upstairs       0.99      1.00      0.99       267\n",
            "\n",
            "          accuracy                           0.97      1942\n",
            "         macro avg       0.93      0.92      0.92      1942\n",
            "      weighted avg       0.97      0.97      0.97      1942\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFyaNtWKby0O"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}